# -*- coding: utf-8 -*-
"""ML_kmerBin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O7lzDL5eDkn8Ag7D8OljvYS0t5fNzCPN
"""

CAMI_dataset='4mers_table_low.csv';
test_size=0.2;
colores=['lightblue','coral','lightcoral','lightgreen']

"""
# **cami_dataset**
"""

def namesGen():
  names=[]
  names.append('Seq_id')
  for i in range(256):
    name='Kmer_'+str(i)
    names.append(name)
  names.append('Tax_id')
  return names

def printInfo(df_input):
  print(df_input.head())
  print('...')
  print(df_input.tail())
  print(df_input.describe())
  print(df_input.info())

import pandas as pd
import collections
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
names=namesGen()
df = pd.read_csv(CAMI_dataset,names=names)
printInfo(df)

"""# **Normalización**"""

from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
#Tax_id to class number 
i=1
finalClass={}
numClass=len(df['Tax_id'].unique())
for items in df['Tax_id'].unique():
  finalClass[items]=i
  i+=1
print(finalClass)
for values in finalClass:
  df['Tax_id'] = df['Tax_id'].replace([values],finalClass[values])

#Normalizing numeric features and converting back to dataframe
numeric_feats= names[1:-1]
df_categ_feats = df.drop(columns = numeric_feats)
df_numeric_feats = pd.DataFrame(df, columns = numeric_feats)
min_max_scaler = preprocessing.MinMaxScaler()
normalized_numeric_feats = min_max_scaler.fit_transform(df_numeric_feats)
normalized_numeric_feats = pd.DataFrame(normalized_numeric_feats, columns = numeric_feats, index=df_categ_feats.index)
df_numeric_norm = pd.concat([df_categ_feats, normalized_numeric_feats], axis=1)
printInfo(df_numeric_norm)

import matplotlib.pyplot as plt
import numpy as np
print(df_numeric_norm['Tax_id'].value_counts().sort_index())
ax=df_numeric_norm['Tax_id'].value_counts().plot(kind='bar')
for p in ax.patches:
  if p.get_height()>1400:
    ax.annotate(str(int(p.get_height())), (p.get_x(), p.get_height()))

plt.xticks(np.arange(0,310, step=15))
plt.ylabel('Número de contigs')
plt.xlabel('Etiqueta (Tax_id)')
plt.grid()
plt.tight_layout()
#plt.savefig("cami_high_taxID_freq.png", dpi=300)

import matplotlib.pyplot as plt
i=0
for (columnName, columnData) in df.iteritems(): 
  if(columnName.startswith('Kmer_')):
    #print('Colunm Name : ', columnName) 
    plt.bar(i,color='darkcyan',height=df[columnName].mean(),width=2)
    i+=1
plt.ylabel('Promedio de ocurrencia')
plt.xlabel('Kmer')
plt.grid()
plt.tight_layout()
#plt.savefig("cami_high_kmer_freq.png", dpi=300)

"""# **Clasificadores**"""

from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import plot_confusion_matrix
import sklearn.metrics as skm
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn import datasets, metrics
import collections, numpy
import seaborn as sns
import matplotlib.pyplot as plt

x=df_numeric_norm.drop(['Seq_id','Tax_id'], axis=1)
y=df_numeric_norm['Tax_id'].values
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size)
print('X_train size: ',len(X_train))
print('X_test size: ',len(X_test))
print()
print("Total clases en data train:\n",collections.Counter(y_train));
print("Total clases en data test:\n",collections.Counter(y_test));

def runClassifier(modelo, name):
  modelo.fit(X_train, y_train)
  y_pred= modelo.predict(X_test)
  df_result=pd.DataFrame(skm.classification_report(y_test,y_pred,output_dict=True))
  df_result=df_result.T
  labels=[]
  labels.append(1)
  for i in range(len(collections.Counter(y_test))+1):
    i+=1
    if i%20==0:
      labels.append(i)
    else:  
      labels.append('')
  #print(df_result)
  #print(confusion_matrix(y_test, y_pred))
  plot_confusion_matrix(modelo, X_test, y_test,include_values=False,
                      xticks_rotation='vertical',normalize='pred', 
                      cmap='Blues',colorbar=True,values_format='.2',display_labels=labels) 
  #metrics.plot_roc_curve(modelo, X_test, y_test) 
  plt.savefig(CAMI_dataset+'_'+name+"_confusionMatrix.svg",format='svg')
  return df_result

"""**KNN**"""

knn = KNeighborsClassifier(n_jobs=-1)
df_knn=runClassifier(knn,'knn')

"""**Random Forest classifier**"""

rf = RandomForestClassifier(n_jobs=-1)
df_rf=runClassifier(rf,'rf')

"""**Logistic_Regression_classifier**"""

LR = LogisticRegression(n_jobs=-1)
df_lr=runClassifier(LR,'lr')

"""**Neuronal Network**"""

mlp=MLPClassifier()
df_nn=runClassifier(mlp,'nn')

"""# **F1-score plot**"""

def plotF1_score(df_in,name,color):
  df_plot=df_in.drop(['accuracy','macro avg','weighted avg'])
  x=df_plot.index
  #df_plot=df_plot.sort_values(by=['support'])
  #print(df_plot)

  y=df_plot['f1-score'].sort_values()
  plt.plot(x,y,label=name,color=color)

plotF1_score(df_knn,'KNN',colores[0])
plotF1_score(df_rf,'RF',colores[1])
#plotF1_score(df_lr,'LR',colores[2])
plotF1_score(df_nn,'NN',colores[3])
plt.grid()
plt.xlabel('Total Class')
plt.ylabel('F1-score')
plt.legend()
plt.tight_layout()
#plt.savefig(CAMI_dataset+"_f1_support.png", dpi=300)

def plotF1andsupp(df_in,name,color):
  df_plot=df_in.drop(['accuracy','macro avg','weighted avg'])
  x=df_plot.index
  df_plot=df_plot.sort_values(by=['f1-score'])
  y=df_plot['f1-score']
  s=df_plot['support']
  s=500*(s/max(s))
  plt.scatter(x,y,s=s,color=color)

plotF1andsupp(df_knn,'KNN',colores[0])
plotF1_score(df_knn,'KNN',colores[0])
plotF1andsupp(df_rf,'RF',colores[1])
plotF1_score(df_rf,'RF',colores[1])
#plotF1andsupp(df_lr,'LR',colores[2])
#plotF1_score(df_lr,'LR',colores[2])
plotF1andsupp(df_nn,'NN',colores[3])
plotF1_score(df_nn,'NN',colores[3])
plt.grid()
plt.xlabel('Total_class')
plt.ylabel('F1-score')
plt.legend()
plt.tight_layout()
#plt.savefig(CAMI_dataset+"_f1andsize.svg", format='svg')

def histF1score(df_in,name):
  df_plot=df_in.drop(['accuracy','macro avg','weighted avg'])
  df_plot['f1-score'].plot.hist(bins=12, alpha=0.5, label=name)

histF1score(df_knn,'knn')
histF1score(df_rf,'rf')
#histF1score(df_lr,'lr')
histF1score(df_nn,'nn')
plt.grid()
plt.xlabel('F1-score')
#plt.ylabel('')
plt.legend()
#plt.savefig(CAMI_dataset+"_f1Hist.svg", format='svg')

def plotF1andtaxid(df_in,name):
  df_plot=df_in.drop(['accuracy','macro avg','weighted avg'])
  #df_plot=df_plot.sort_values(by=['f1-score'],ascending=True)
  x=df_plot.index
  y=df_plot['f1-score']
  s=df_plot['support']
  s=1000*(s/max(s))
  plt.scatter(y,x,label=name,marker='.',s=s)

plotF1andtaxid(df_knn,'KNN')
plotF1andtaxid(df_rf,'RF')
#plotF1andtaxid(df_lr,'lr')
plotF1andtaxid(df_nn,'NN')
labels=[]
locs=[]
labels.append(1)
for i in range(len(df_nn['support'])):
  locs.append(i)
  i+=1
  if i%20==0: 
    labels.append(i)
  else:  
    labels.append('')
#locs, labels2 =plt.xticks() 
plt.yticks(locs,labels) 
plt.tight_layout()
#plt.grid()
plt.ylabel('Taxid')
plt.xlabel('F1-score')
plt.legend()
plt.savefig(CAMI_dataset+"_taxId_f1andsize.svg", format='svg')